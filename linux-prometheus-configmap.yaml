apiVersion: v1
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: kubemon-prometheus-config
  labels:
    app.kubernetes.io/name: kubemon
    app.kubernetes.io/component: prometheus
data:
  # If you'd like to add your own alerts or modify existing alerts, you can edit this ConfigMap value.
  alerts.yaml: |-
    "groups": 
    - name: apps-rules
      rules:
      - alert: JVMThread
        expr: jvm_threads_current{job="kubernetes-pods",namespace="default",pod!=""} >= 30
        for: 1m
        labels:
          severity: restartpod
        annotations:
          messages: "Current jvm threads of POD {{ $labels.pod }} in namespace {{ $labels.namespace }} is above 30 (current value: {{ $value }}%)"
          severity: restartpod
      - alert: JVMDeadlockThread
        expr: jvm_threads_deadlocked{job="kubernetes-pods",namespace="piggyapp",pod!=""} >= 1
        for: 1m
        labels:
          severity: restartpod
        annotations:
          messages: "Current jvm deadlock threads of POD {{ $labels.pod }} in namespace {{ $labels.namespace }} is above 0 (current value: {{ $value }}%)"
          severity: restartpod          
      - alert: PODMemory
        expr: sum(container_memory_usage_bytes{namespace="demomem", container_name!=""}) by (pod,namespace) / 1024 / 1024 > 75
        for: 1m
        labels:
          severity: scalepod
        annotations:
          messages: "Current memory of POD {{ $labels.pod }} in namespace {{ $labels.namespace }} is above 75 MB (current value: {{ $value }}%)"
          severity: scalepod
    - "name": "kubernetes-absent"
      "rules": 
      - "alert": "KubeAPIDown"
        "annotations": 
          "message": "KubeAPI has disappeared from Prometheus target discovery."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapidown"
        "expr": |
          absent(up{job="apiserver"} == 1)
        "for": "15m"
        "labels": 
          "severity": "critical"
      - "alert": "KubeControllerManagerDown"
        "annotations": 
          "message": "KubeControllerManager has disappeared from Prometheus target discovery."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontrollermanagerdown"
        "expr": |
          kube_pod_container_status_running{container="kube-controller-manager",namespace="kube-system"} == 0
        "for": "15m"
        "labels": 
          "severity": "critical"
      - "alert": "KubeSchedulerDown"
        "annotations": 
          "message": "KubeScheduler has disappeared from Prometheus target discovery."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeschedulerdown"
        "expr": |
          kube_pod_container_status_running{container="kube-scheduler",namespace="kube-system"} == 0
        "for": "15m"
        "labels": 
          "severity": "critical"
      - "alert": "KubeletDown"
        "annotations": 
          "message": "Kubelet has disappeared from Prometheus target discovery."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletdown"
        "expr": |
          absent(up{job="kubelet"} == 1)
        "for": "15m"
        "labels": 
          "severity": "critical"
    - "name": "kubernetes-apps"
      "rules": 
      - "alert": "KubePodCrashLooping"
        "annotations": 
          "message": "Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is restarting {{ printf \"%.2f\" $value }} times / 5 minutes."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping"
        "expr": |
          rate(kube_pod_container_status_restarts_total{job="kube-state-metrics"}[15m]) * 60 * 5 > 0
        "for": "1h"
        "labels": 
          "severity": "critical"
      - "alert": "KubePodNotReady"
        "annotations": 
          "message": "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than an hour."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready"
        "expr": |
          sum by (namespace, pod) (kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown"}) > 0
        "for": "1h"
        "labels": 
          "severity": "critical"
      - "alert": "KubeDeploymentGenerationMismatch"
        "annotations": 
          "message": "Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match, this indicates that the Deployment has failed but has not been rolled back."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentgenerationmismatch"
        "expr": |
          kube_deployment_status_observed_generation{job="kube-state-metrics"}
            !=
          kube_deployment_metadata_generation{job="kube-state-metrics"}
        "for": "15m"
        "labels": 
          "severity": "critical"
      - "alert": "KubeDeploymentReplicasMismatch"
        "annotations": 
          "message": "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than an hour."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentreplicasmismatch"
        "expr": |
          kube_deployment_spec_replicas{job="kube-state-metrics"}
            !=
          kube_deployment_status_replicas_available{job="kube-state-metrics"}
        "for": "1h"
        "labels": 
          "severity": "critical"
      - "alert": "KubeStatefulSetReplicasMismatch"
        "annotations": 
          "message": "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"
        "expr": |
          kube_statefulset_status_replicas_ready{job="kube-state-metrics"}
            !=
          kube_statefulset_status_replicas{job="kube-state-metrics"}
        "for": "15m"
        "labels": 
          "severity": "critical"
      - "alert": "KubeStatefulSetGenerationMismatch"
        "annotations": 
          "message": "StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match, this indicates that the StatefulSet has failed but has not been rolled back."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetgenerationmismatch"
        "expr": |
          kube_statefulset_status_observed_generation{job="kube-state-metrics"}
            !=
          kube_statefulset_metadata_generation{job="kube-state-metrics"}
        "for": "15m"
        "labels": 
          "severity": "critical"
      - "alert": "KubeStatefulSetUpdateNotRolledOut"
        "annotations": 
          "message": "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetupdatenotrolledout"
        "expr": |
          max without (revision) (
            kube_statefulset_status_current_revision{job="kube-state-metrics"}
              unless
            kube_statefulset_status_update_revision{job="kube-state-metrics"}
          )
            *
          (
            kube_statefulset_replicas{job="kube-state-metrics"}
              !=
            kube_statefulset_status_replicas_updated{job="kube-state-metrics"}
          )
        "for": "15m"
        "labels": 
          "severity": "critical"
      - "alert": "KubeDaemonSetRolloutStuck"
        "annotations": 
          "message": "Only {{ $value }}% of the desired Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are scheduled and ready."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetrolloutstuck"
        "expr": |
          kube_daemonset_status_number_ready{job="kube-state-metrics"}
            /
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"} * 100 < 100
        "for": "15m"
        "labels": 
          "severity": "critical"
      - "alert": "KubeDaemonSetNotScheduled"
        "annotations": 
          "message": "{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled"
        "expr": |
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
            -
          kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0
        "for": "10m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeDaemonSetMisScheduled"
        "annotations": 
          "message": "{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetmisscheduled"
        "expr": |
          kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0
        "for": "10m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeCronJobRunning"
        "annotations": 
          "message": "CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is taking more than 1h to complete."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecronjobrunning"
        "expr": |
          time() - kube_cronjob_next_schedule_time{job="kube-state-metrics"} > 3600
        "for": "1h"
        "labels": 
          "severity": "warning"
      - "alert": "KubeJobCompletion"
        "annotations": 
          "message": "Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than one hour to complete."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobcompletion"
        "expr": |
          kube_job_spec_completions{job="kube-state-metrics"} - kube_job_status_succeeded{job="kube-state-metrics"}  > 0
        "for": "1h"
        "labels": 
          "severity": "warning"
      - "alert": "KubeJobFailed"
        "annotations": 
          "message": "Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobfailed"
        "expr": |
          kube_job_status_failed{job="kube-state-metrics"}  > 0
        "for": "1h"
        "labels": 
          "severity": "warning"
    - "name": "kubernetes-resources"
      "rules": 
      - "alert": "KubeCPUOvercommit"
        "annotations": 
          "message": "Cluster has overcommitted CPU resource requests for Pods and cannot tolerate node failure."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit"
        "expr": |
          sum(namespace_name:kube_pod_container_resource_requests_cpu_cores:sum)
            /
          sum(node:node_num_cpu:sum)
            >
          (count(node:node_num_cpu:sum)-1) / count(node:node_num_cpu:sum)
        "for": "5m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeMemOvercommit"
        "annotations": 
          "message": "Cluster has overcommitted memory resource requests for Pods and cannot tolerate node failure."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememovercommit"
        "expr": |
          sum(namespace_name:kube_pod_container_resource_requests_memory_bytes:sum)
            /
          sum(node_memory_MemTotal_bytes)
            >
          (count(node:node_num_cpu:sum)-1)
            /
          count(node:node_num_cpu:sum)
        "for": "5m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeCPUOvercommit"
        "annotations": 
          "message": "Cluster has overcommitted CPU resource requests for Namespaces."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit"
        "expr": |
          sum(kube_resourcequota{job="kube-state-metrics", type="hard", resource="cpu"})
            /
          sum(node:node_num_cpu:sum)
            > 1.5
        "for": "5m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeMemOvercommit"
        "annotations": 
          "message": "Cluster has overcommitted memory resource requests for Namespaces."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememovercommit"
        "expr": |
          sum(kube_resourcequota{job="kube-state-metrics", type="hard", resource="memory"})
            /
          sum(node_memory_MemTotal_bytes{job="node-exporter"})
            > 1.5
        "for": "5m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeQuotaExceeded"
        "annotations": 
          "message": "Namespace {{ $labels.namespace }} is using {{ printf \"%0.0f\" $value }}% of its {{ $labels.resource }} quota."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaexceeded"
        "expr": |
          100 * kube_resourcequota{job="kube-state-metrics", type="used"}
            / ignoring(instance, job, type)
          (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
            > 90
        "for": "15m"
        "labels": 
          "severity": "warning"
      - "alert": "CPUThrottlingHigh"
        "annotations": 
          "message": "{{ printf \"%0.0f\" $value }}% throttling of CPU in namespace {{ $labels.namespace }} for container {{ $labels.container_name }} in pod {{ $labels.pod_name }}."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-cputhrottlinghigh"
        "expr": |
          100 * sum(increase(container_cpu_cfs_throttled_periods_total{container_name!="", }[5m])) by (container_name, pod_name, namespace)
            /
          sum(increase(container_cpu_cfs_periods_total{}[5m])) by (container_name, pod_name, namespace)
            > 25 
        "for": "15m"
        "labels": 
          "severity": "warning"
    - "name": "kubernetes-storage"
      "rules": 
      - "alert": "KubePersistentVolumeUsageCritical"
        "annotations": 
          "message": "The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} is only {{ printf \"%0.2f\" $value }}% free."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeusagecritical"
        "expr": |
          100 * kubelet_volume_stats_available_bytes{job="kubelet"}
            /
          kubelet_volume_stats_capacity_bytes{job="kubelet"}
            < 3
        "for": "1m"
        "labels": 
          "severity": "critical"
      - "alert": "KubePersistentVolumeFullInFourDays"
        "annotations": 
          "message": "Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} is expected to fill up within four days. Currently {{ printf \"%0.2f\" $value }}% is available."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumefullinfourdays"
        "expr": |
          100 * (
            kubelet_volume_stats_available_bytes{job="kubelet"}
              /
            kubelet_volume_stats_capacity_bytes{job="kubelet"}
          ) < 15
          and
          predict_linear(kubelet_volume_stats_available_bytes{job="kubelet"}[6h], 4 * 24 * 3600) < 0
        "for": "5m"
        "labels": 
          "severity": "critical"
      - "alert": "KubePersistentVolumeErrors"
        "annotations": 
          "message": "The persistent volume {{ $labels.persistentvolume }} has status {{ $labels.phase }}."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeerrors"
        "expr": |
          kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0
        "for": "5m"
        "labels": 
          "severity": "critical"
    - "name": "kubernetes-system"
      "rules": 
      - "alert": "KubeNodeNotReady"
        "annotations": 
          "message": "{{ $labels.node }} has been unready for more than an hour."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodenotready"
        "expr": |
          kube_node_status_condition{job="kube-state-metrics",condition="Ready",status="true"} == 0
        "for": "1h"
        "labels": 
          "severity": "warning"
      - "alert": "KubeVersionMismatch"
        "annotations": 
          "message": "There are {{ $value }} different semantic versions of Kubernetes components running."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeversionmismatch"
        "expr": |
          count(count by (gitVersion) (label_replace(kubernetes_build_info{job!="kube-dns"},"gitVersion","$1","gitVersion","(v[0-9]*.[0-9]*.[0-9]*).*"))) > 1
        "for": "1h"
        "labels": 
          "severity": "warning"
      - "alert": "KubeClientErrors"
        "annotations": 
          "message": "Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ printf \"%0.0f\" $value }}% errors.'"
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors"
        "expr": |
          (sum(rate(rest_client_requests_total{code=~"5.."}[5m])) by (instance, job)
            /
          sum(rate(rest_client_requests_total[5m])) by (instance, job))
          * 100 > 1
        "for": "15m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeClientErrors"
        "annotations": 
          "message": "Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ printf \"%0.0f\" $value }} errors / second."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors"
        "expr": |
          sum(rate(ksm_scrape_error_total{job="kube-state-metrics"}[5m])) by (instance, job) > 0.1
        "for": "15m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeletTooManyPods"
        "annotations": 
          "message": "Kubelet {{ $labels.instance }} is running {{ $value }} Pods, close to the limit of 110."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubelettoomanypods"
        "expr": |
          kubelet_running_pod_count{job="kubelet"} > 110 * 0.9
        "for": "15m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeAPILatencyHigh"
        "annotations": 
          "message": "The API server has a 99th percentile latency of {{ $value }} seconds for {{ $labels.verb }} {{ $labels.resource }}."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapilatencyhigh"
        "expr": |
          cluster_quantile:apiserver_request_latencies:histogram_quantile{job="apiserver",quantile="0.99",subresource!="log",verb!~"^(?:LIST|WATCH|WATCHLIST|PROXY|CONNECT)$"} > 1
        "for": "10m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeAPILatencyHigh"
        "annotations": 
          "message": "The API server has a 99th percentile latency of {{ $value }} seconds for {{ $labels.verb }} {{ $labels.resource }}."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapilatencyhigh"
        "expr": |
          cluster_quantile:apiserver_request_latencies:histogram_quantile{job="apiserver",quantile="0.99",subresource!="log",verb!~"^(?:LIST|WATCH|WATCHLIST|PROXY|CONNECT)$"} > 4
        "for": "10m"
        "labels": 
          "severity": "critical"
      - "alert": "KubeAPIErrorsHigh"
        "annotations": 
          "message": "API server is returning errors for {{ $value }}% of requests."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh"
        "expr": |
          sum(rate(apiserver_request_count{job="apiserver",code=~"^(?:5..)$"}[5m]))
            /
          sum(rate(apiserver_request_count{job="apiserver"}[5m])) * 100 > 3
        "for": "10m"
        "labels": 
          "severity": "critical"
      - "alert": "KubeAPIErrorsHigh"
        "annotations": 
          "message": "API server is returning errors for {{ $value }}% of requests."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh"
        "expr": |
          sum(rate(apiserver_request_count{job="apiserver",code=~"^(?:5..)$"}[5m]))
            /
          sum(rate(apiserver_request_count{job="apiserver"}[5m])) * 100 > 1
        "for": "10m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeAPIErrorsHigh"
        "annotations": 
          "message": "API server is returning errors for {{ $value }}% of requests for {{ $labels.verb }} {{ $labels.resource }} {{ $labels.subresource }}."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh"
        "expr": |
          sum(rate(apiserver_request_count{job="apiserver",code=~"^(?:5..)$"}[5m])) by (resource,subresource,verb)
            /
          sum(rate(apiserver_request_count{job="apiserver"}[5m])) by (resource,subresource,verb) * 100 > 10
        "for": "10m"
        "labels": 
          "severity": "critical"
      - "alert": "KubeAPIErrorsHigh"
        "annotations": 
          "message": "API server is returning errors for {{ $value }}% of requests for {{ $labels.verb }} {{ $labels.resource }} {{ $labels.subresource }}."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorshigh"
        "expr": |
          sum(rate(apiserver_request_count{job="apiserver",code=~"^(?:5..)$"}[5m])) by (resource,subresource,verb)
            /
          sum(rate(apiserver_request_count{job="apiserver"}[5m])) by (resource,subresource,verb) * 100 > 5
        "for": "10m"
        "labels": 
          "severity": "warning"
      - "alert": "KubeClientCertificateExpiration"
        "annotations": 
          "message": "A client certificate used to authenticate to the apiserver is expiring in less than 7.0 days."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration"
        "expr": |
          apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 604800
        "labels": 
          "severity": "warning"
      - "alert": "KubeClientCertificateExpiration"
        "annotations": 
          "message": "A client certificate used to authenticate to the apiserver is expiring in less than 24.0 hours."
          "runbook_url": "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration"
        "expr": |
          apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 86400
        "labels": 
          "severity": "critical"
  rules.yaml: |-
    "groups": 
    - "name": "k8s.rules"
      "rules": 
      - "expr": |
          sum(rate(container_cpu_usage_seconds_total{job="cadvisor", image!="", container_name!=""}[5m])) by (namespace)
        "record": "namespace:container_cpu_usage_seconds_total:sum_rate"
      - "expr": |
          sum by (namespace, pod_name, container_name) (
            rate(container_cpu_usage_seconds_total{job="cadvisor", image!="", container_name!=""}[5m])
          )
        "record": "namespace_pod_name_container_name:container_cpu_usage_seconds_total:sum_rate"
      - "expr": |
          sum(container_memory_usage_bytes{job="cadvisor", image!="", container_name!=""}) by (namespace)
        "record": "namespace:container_memory_usage_bytes:sum"
      - "expr": |
          sum by (namespace, label_name) (
             sum(rate(container_cpu_usage_seconds_total{job="cadvisor", image!="", container_name!=""}[5m])) by (namespace, pod_name)
           * on (namespace, pod_name) group_left(label_name)
             label_replace(kube_pod_labels{job="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
          )
        "record": "namespace_name:container_cpu_usage_seconds_total:sum_rate"
      - "expr": |
          sum by (namespace, label_name) (
            sum(container_memory_usage_bytes{job="cadvisor",image!="", container_name!=""}) by (pod_name, namespace)
          * on (namespace, pod_name) group_left(label_name)
            label_replace(kube_pod_labels{job="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
          )
        "record": "namespace_name:container_memory_usage_bytes:sum"
      - "expr": |
          sum by (namespace, label_name) (
            sum(kube_pod_container_resource_requests_memory_bytes{job="kube-state-metrics"} * on (endpoint, instance, job, namespace, pod, service) group_left(phase) (kube_pod_status_phase{phase=~"^(Pending|Running)$"} == 1)) by (namespace, pod)
          * on (namespace, pod) group_left(label_name)
            label_replace(kube_pod_labels{job="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
          )
        "record": "namespace_name:kube_pod_container_resource_requests_memory_bytes:sum"
      - "expr": |
          sum by (namespace, label_name) (
            sum(kube_pod_container_resource_requests_cpu_cores{job="kube-state-metrics"} * on (endpoint, instance, job, namespace, pod, service) group_left(phase) (kube_pod_status_phase{phase=~"^(Pending|Running)$"} == 1)) by (namespace, pod)
          * on (namespace, pod) group_left(label_name)
            label_replace(kube_pod_labels{job="kube-state-metrics"}, "pod_name", "$1", "pod", "(.*)")
          )
        "record": "namespace_name:kube_pod_container_resource_requests_cpu_cores:sum"
      - "expr": |
          sum(
            label_replace(
              label_replace(
                kube_pod_owner{job="kube-state-metrics", owner_kind="ReplicaSet"},
                "replicaset", "$1", "owner_name", "(.*)"
              ) * on(replicaset, namespace) group_left(owner_name) kube_replicaset_owner{job="kube-state-metrics"},
              "workload", "$1", "owner_name", "(.*)"
            )
          ) by (namespace, workload, pod)
        "labels": 
          "workload_type": "deployment"
        "record": "mixin_pod_workload"
      - "expr": |
          sum(
            label_replace(
              kube_pod_owner{job="kube-state-metrics", owner_kind="DaemonSet"},
              "workload", "$1", "owner_name", "(.*)"
            )
          ) by (namespace, workload, pod)
        "labels": 
          "workload_type": "daemonset"
        "record": "mixin_pod_workload"
      - "expr": |
          sum(
            label_replace(
              kube_pod_owner{job="kube-state-metrics", owner_kind="StatefulSet"},
              "workload", "$1", "owner_name", "(.*)"
            )
          ) by (namespace, workload, pod)
        "labels": 
          "workload_type": "statefulset"
        "record": "mixin_pod_workload"
    - "name": "kube-scheduler.rules"
      "rules": 
      - "expr": |
          histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.99"
        "record": "cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.99"
        "record": "cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.99, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.99"
        "record": "cluster_quantile:scheduler_binding_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.9"
        "record": "cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.9"
        "record": "cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.9, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.9"
        "record": "cluster_quantile:scheduler_binding_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.5"
        "record": "cluster_quantile:scheduler_e2e_scheduling_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.5"
        "record": "cluster_quantile:scheduler_scheduling_algorithm_latency:histogram_quantile"
      - "expr": |
          histogram_quantile(0.5, sum(rate(scheduler_binding_latency_microseconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.5"
        "record": "cluster_quantile:scheduler_binding_latency:histogram_quantile"
    - "name": "kube-apiserver.rules"
      "rules": 
      - "expr": |
          histogram_quantile(0.99, sum(rate(apiserver_request_latencies_bucket{job="apiserver"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.99"
        "record": "cluster_quantile:apiserver_request_latencies:histogram_quantile"
      - "expr": |
          histogram_quantile(0.9, sum(rate(apiserver_request_latencies_bucket{job="apiserver"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.9"
        "record": "cluster_quantile:apiserver_request_latencies:histogram_quantile"
      - "expr": |
          histogram_quantile(0.5, sum(rate(apiserver_request_latencies_bucket{job="apiserver"}[5m])) without(instance, pod)) / 1e+06
        "labels": 
          "quantile": "0.5"
        "record": "cluster_quantile:apiserver_request_latencies:histogram_quantile"
    - "name": "node.rules"
      "rules": 
      - "expr": "sum(min(kube_pod_info) by (node))"
        "record": ":kube_pod_info_node_count:"
      - "expr": |
          max(label_replace(kube_pod_info{job="kube-state-metrics"}, "pod", "$1", "pod", "(.*)")) by (node, namespace, pod)
        "record": "node_namespace_pod:kube_pod_info:"
      - "expr": |
          count by (node) (sum by (node, cpu) (
            node_cpu_seconds_total{job="node-exporter"}
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          ))
        "record": "node:node_num_cpu:sum"
      - "expr": |
          1 - avg(rate(node_cpu_seconds_total{job="node-exporter",mode="idle"}[1m]))
        "record": ":node_cpu_utilisation:avg1m"
      - "expr": |
          1 - avg by (node) (
            rate(node_cpu_seconds_total{job="node-exporter",mode="idle"}[1m])
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:)
        "record": "node:node_cpu_utilisation:avg1m"
      - "expr": |
          node:node_cpu_utilisation:avg1m
            *
          node:node_num_cpu:sum
            /
          scalar(sum(node:node_num_cpu:sum))
        "record": "node:cluster_cpu_utilisation:ratio"
      - "expr": |
          sum(node_load1{job="node-exporter"})
          /
          sum(node:node_num_cpu:sum)
        "record": ":node_cpu_saturation_load1:"
      - "expr": |
          sum by (node) (
            node_load1{job="node-exporter"}
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
          /
          node:node_num_cpu:sum
        "record": "node:node_cpu_saturation_load1:"
      - "expr": |
          1 -
          sum(node_memory_MemFree_bytes{job="node-exporter"} + node_memory_Cached_bytes{job="node-exporter"} + node_memory_Buffers_bytes{job="node-exporter"})
          /
          sum(node_memory_MemTotal_bytes{job="node-exporter"})
        "record": ":node_memory_utilisation:"
      - "expr": |
          sum(node_memory_MemFree_bytes{job="node-exporter"} + node_memory_Cached_bytes{job="node-exporter"} + node_memory_Buffers_bytes{job="node-exporter"})
        "record": ":node_memory_MemFreeCachedBuffers_bytes:sum"
      - "expr": |
          sum(node_memory_MemTotal_bytes{job="node-exporter"})
        "record": ":node_memory_MemTotal_bytes:sum"
      - "expr": |
          sum by (node) (
            (node_memory_MemFree_bytes{job="node-exporter"} + node_memory_Cached_bytes{job="node-exporter"} + node_memory_Buffers_bytes{job="node-exporter"})
            * on (namespace, pod) group_left(node)
              node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_memory_bytes_available:sum"
      - "expr": |
          sum by (node) (
            node_memory_MemTotal_bytes{job="node-exporter"}
            * on (namespace, pod) group_left(node)
              node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_memory_bytes_total:sum"
      - "expr": |
          (node:node_memory_bytes_total:sum - node:node_memory_bytes_available:sum)
          /
          node:node_memory_bytes_total:sum
        "record": "node:node_memory_utilisation:ratio"
      - "expr": |
          (node:node_memory_bytes_total:sum - node:node_memory_bytes_available:sum)
          /
          scalar(sum(node:node_memory_bytes_total:sum))
        "record": "node:cluster_memory_utilisation:ratio"
      - "expr": |
          1e3 * sum(
            (rate(node_vmstat_pgpgin{job="node-exporter"}[1m])
           + rate(node_vmstat_pgpgout{job="node-exporter"}[1m]))
          )
        "record": ":node_memory_swap_io_bytes:sum_rate"
      - "expr": |
          1 -
          sum by (node) (
            (node_memory_MemFree_bytes{job="node-exporter"} + node_memory_Cached_bytes{job="node-exporter"} + node_memory_Buffers_bytes{job="node-exporter"})
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
          /
          sum by (node) (
            node_memory_MemTotal_bytes{job="node-exporter"}
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_memory_utilisation:"
      - "expr": |
          1 - (node:node_memory_bytes_available:sum / node:node_memory_bytes_total:sum)
        "record": "node:node_memory_utilisation_2:"
      - "expr": |
          1e3 * sum by (node) (
            (rate(node_vmstat_pgpgin{job="node-exporter"}[1m])
           + rate(node_vmstat_pgpgout{job="node-exporter"}[1m]))
           * on (namespace, pod) group_left(node)
             node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_memory_swap_io_bytes:sum_rate"
      - "expr": |
          avg(irate(node_disk_io_time_seconds_total{job="node-exporter",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m]))
        "record": ":node_disk_utilisation:avg_irate"
      - "expr": |
          avg by (node) (
            irate(node_disk_io_time_seconds_total{job="node-exporter",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m])
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_disk_utilisation:avg_irate"
      - "expr": |
          avg(irate(node_disk_io_time_weighted_seconds_total{job="node-exporter",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m]))
        "record": ":node_disk_saturation:avg_irate"
      - "expr": |
          avg by (node) (
            irate(node_disk_io_time_weighted_seconds_total{job="node-exporter",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m])
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_disk_saturation:avg_irate"
      - "expr": |
          max by (instance, namespace, pod, device) ((node_filesystem_size_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"}
          - node_filesystem_avail_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"})
          / node_filesystem_size_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"})
        "record": "node:node_filesystem_usage:"
      - "expr": |
          max by (instance, namespace, pod, device) (node_filesystem_avail_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"} / node_filesystem_size_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"})
        "record": "node:node_filesystem_avail:"
      - "expr": |
          sum(irate(node_network_receive_bytes_total{job="node-exporter",device!~"veth.+"}[1m])) +
          sum(irate(node_network_transmit_bytes_total{job="node-exporter",device!~"veth.+"}[1m]))
        "record": ":node_net_utilisation:sum_irate"
      - "expr": |
          sum by (node) (
            (irate(node_network_receive_bytes_total{job="node-exporter",device!~"veth.+"}[1m]) +
            irate(node_network_transmit_bytes_total{job="node-exporter",device!~"veth.+"}[1m]))
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_net_utilisation:sum_irate"
      - "expr": |
          sum(irate(node_network_receive_drop_total{job="node-exporter",device!~"veth.+"}[1m])) +
          sum(irate(node_network_transmit_drop_total{job="node-exporter",device!~"veth.+"}[1m]))
        "record": ":node_net_saturation:sum_irate"
      - "expr": |
          sum by (node) (
            (irate(node_network_receive_drop_total{job="node-exporter",device!~"veth.+"}[1m]) +
            irate(node_network_transmit_drop_total{job="node-exporter",device!~"veth.+"}[1m]))
          * on (namespace, pod) group_left(node)
            node_namespace_pod:kube_pod_info:
          )
        "record": "node:node_net_saturation:sum_irate"
      - "expr": |
          max(
            max(
              kube_pod_info{job="kube-state-metrics", host_ip!=""}
            ) by (node, host_ip)
            * on (host_ip) group_right (node)
            label_replace(
              (max(node_filesystem_files{job="node-exporter", mountpoint="/"}) by (instance)), "host_ip", "$1", "instance", "(.*):.*"
            )
          ) by (node)
        "record": "node:node_inodes_total:"
      - "expr": |
          max(
            max(
              kube_pod_info{job="kube-state-metrics", host_ip!=""}
            ) by (node, host_ip)
            * on (host_ip) group_right (node)
            label_replace(
              (max(node_filesystem_files_free{job="node-exporter", mountpoint="/"}) by (instance)), "host_ip", "$1", "instance", "(.*):.*"
            )
          ) by (node)
        "record": "node:node_inodes_free:"
  prometheus.yaml: |-
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 1m
    alerting:
      alertmanagers:
      - kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
            - monitoring
        scheme: http
        path_prefix: /
        timeout: 10s
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_label_k8s_app]
          separator: ;
          regex: monitoring;alertmanager
          replacement: $1
          action: keep
        - source_labels: [__meta_kubernetes_endpoint_port_name]
          separator: ;
          regex: http
          replacement: $1
          action: keep
    rule_files:
    - /etc/config/rules.yaml
    - /etc/config/alerts.yaml
    scrape_configs:
    - job_name: kubernetes-service-endpoints
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_service_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        separator: ;
        regex: "true"
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        separator: ;
        regex: (.+)
        target_label: __metrics_path__
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
        separator: ;
        regex: (https?)
        target_label: __scheme__
        replacement: $1
        action: replace
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        separator: ;
        regex: ([^:]+)(?::\d+)?;(\d+)
        target_label: __address__
        replacement: $1:$2
        action: replace
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: instance
        replacement: $1
        action: replace
    - job_name: kubernetes-services
      honor_timestamps: true
      params:
        module:
        - http_2xx
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /probe
      scheme: http
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_service_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__address__]
        separator: ;
        regex: (.*)
        target_label: __param_target
        replacement: $1
        action: replace
      - separator: ;
        regex: (.*)
        target_label: __address__
        replacement: blackbox
        action: replace
      - source_labels: [__param_target]
        separator: ;
        regex: (.*)
        target_label: instance
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
        separator: ;
        regex: "true"
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
    - job_name: kubernetes-pods
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_pod_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        separator: ;
        regex: "true"
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        separator: ;
        regex: (.+)
        target_label: __metrics_path__
        replacement: $1
        action: replace
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        separator: ;
        regex: ([^:]+)(?::\d+)?;(\d+)
        target_label: __address__
        replacement: $1:$2
        action: replace
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: instance
        replacement: $1
        action: replace
    - job_name: alertmanager
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_service_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__address__]
        separator: ;
        regex: ([^:]+)(?::\d+)?
        target_label: __address__
        replacement: $1:9093
        action: replace
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_label_k8s_app]
        separator: ;
        regex: monitoring;alertmanager
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
    - job_name: apiserver
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_service_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name]
        separator: ;
        regex: default;kubernetes
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        separator: ;
        regex: https
        replacement: $1
        action: keep
    - job_name: kube-state-metrics
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_service_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_label_k8s_app]
        separator: ;
        regex: monitoring;kube-state-metrics
        replacement: $1
        action: keep
    - job_name: node-exporter
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_pod_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__address__]
        separator: ;
        regex: ([^:]+)(?::\d+)?
        target_label: __address__
        replacement: $1:9100
        action: replace
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_k8s_app]
        separator: ;
        regex: monitoring;node-exporter
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: (.*)
        target_label: instance
        replacement: $1
        action: replace
    - job_name: prometheus
      honor_timestamps: true
      scrape_interval: 15s
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - separator: ;
        regex: __meta_kubernetes_pod_label_(.+)
        replacement: $1
        action: labelmap
      - source_labels: [__address__]
        separator: ;
        regex: ([^:]+)(?::\d+)?
        target_label: __address__
        replacement: $1:9090
        action: replace
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_pod_label_k8s_app]
        separator: ;
        regex: monitoring;prometheus
        replacement: $1
        action: keep
      - source_labels: [__meta_kubernetes_namespace]
        separator: ;
        regex: (.*)
        target_label: namespace
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: pod
        replacement: $1
        action: replace
      - source_labels: [__meta_kubernetes_pod_name]
        separator: ;
        regex: (.*)
        target_label: instance
        replacement: $1
        action: replace
    - job_name: cadvisor
      honor_labels: true
      honor_timestamps: true
      scrape_interval: 30s
      scrape_timeout: 30s
      metrics_path: /metrics/cadvisor
      scheme: https
      kubernetes_sd_configs:
      - role: node
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
    - job_name: kubelet
      honor_labels: true
      honor_timestamps: true
      scrape_interval: 30s
      scrape_timeout: 30s
      metrics_path: /metrics
      scheme: https
      kubernetes_sd_configs:
      - role: node
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
